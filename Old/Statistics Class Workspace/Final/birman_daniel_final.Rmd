---
title: "birman_daniel_final"
author: "Dan Birman"
date: "Wednesday, December 03, 2014"
output: html_document
---
```{r}
library(ggplot2)
library(lme4)
library(lmerTest)
library(reshape2)
pp = function(x) {round(x, digits=3)}
p = function(x) {round(x, digits=2)}
## APA Format Printing
## Author: Dan Birman
## 10/13/2014

apaprint = function(stat_obj, coefs=c(),co=F,stars=F) {
  so = class(stat_obj)
  if (length(so) > 1) {so = so[1]}
  switch(so,
         "htest" = .phtest(stat_obj,stars),
         "lm" = .plm(stat_obj,coefs,co,stars),
         "glm" = .pglm(stat_obj,coefs,stars))
  }

.pglm = function(s,coefs,stars) {
  #Warning this defaults 
  if (length(coefs)==0) {coefs = dimnames(summary(s)$coefficients)[[1]][2]}
  out_s = .lin_mod_coefs(s,coefs,stars)
  out_s
  }

.plm = function(s,coefs,co,stars) {
  sm = summary(s)
  out_s = .lin_mod_coefs(s,coefs,stars)
  if (co) {return(out_s)}
  if (length(coefs)>=1) {paste(out_s,", ",sep="")}
  #Everything standard
  f = sm$fstatistic
  p = pf(f[1],f[2],f[3],lower.tail=F)
  r2 = sm$r.squared
  if (length(coefs)>0) {
    return(sprintf("%s$;  F_{(%.0f, %.0f)} = %.2f, %s, adj. R^2 = %.2f$",out_s,f[2],f[3],f[1],.pformat(p,stars),r2))
    }
  return(sprintf("$F_{(%.0f, %.0f)} = %.2f, %s, adj. R^2 = %.2f$",f[2],f[3],f[1],.pformat(p,stars),r2))
  }

.lin_mod_coefs = function(s,coefs,stars) {
  sm = summary(s)
  co_s = c()
  if (length(coefs) >= 1) {
    for (i in 1:length(coefs)) {
      cur = coefs[i]
      dat = sm$coefficients[cur,]
      p = dat[4]
      ci = confint(s,cur)
      if (i > 1) {co_s = paste(", ",co_s,sep="")}
      co_s = paste(sprintf("$b_{%s} = %.2f, [%.2f %.2f], %s$",cur,dat[1],ci[1],ci[2],.pformat(p,stars)),co_s,sep = "")
      }
    }
  if (length(co_s)==0) {co_s = ""}
  co_s
  }

.pformat = function(pv,stars) {
  if (stars==T) {
    if (pv >= .05) {return(sprintf("p = %.3f",pv))}
    if (pv >= .01) {return(sprintf("p = %.3f *",pv))}
    if (pv >= .001) {return(sprintf("p = %.3f **",pv))}
    return("p < 0.001 ***")
    }
  if (pv >= .05) {return(sprintf("p = %.3f",pv))}
  if (pv >= .01) {return(sprintf("p = %.3f",pv))}
  if (pv >= .001) {return(sprintf("p = %.3f",pv))}
  return("p < 0.001")
  }

.phtest = function(s,stars) {
  switch(s["method"]$method,
         "One Sample t-test" = .pttest(s,stars),
         "Welch Two Sample t-test" = .pttest(s,stars),
         "Pearson's Chi-squared test" = .pchisqp(s,stars),
         "Pearson's Chi-squared test with Yates' continuity correction" = .pchisqp(s,stars),
         "Chi-squared test for given probabilities" = .pchisqp(s,stars),
         "One-way analysis of means (not assuming equal variances)" = .panova(s,stars),
         "Pearson's product-moment correlation" = .pcorr(s,stars)
         )
  }

.panova = function(s,stars) {
  .basicprint(s,"F",stars)
  }

.pchisqp = function(s,stars) {
  sprintf("$\\chi^2$(%.0f, N = %.0f) = %.2f, %s",s$parameter,s$parameter+1,s$statistic,.pformat(s$p.value,stars))
  }

.pcorr = function(s,stars) {
  sprintf("*r* (%.0f) = %.2f, %s",s$parameter,s$estimate,.pformat(s$p.value,stars))
  }

.pttest = function(s,stars) {
  .basicprint(s,"t",stars)
  }

.basicprint = function(s,st,stars) {
  sprintf("*%s* (%.0f) = %.2f, %s",st,s$parameter,s$statistic,.pformat(s$p.value,stars))
  }
```

```{r}
vdata = read.csv("http://web.stanford.edu/class/psych252/data/vocab0.csv")
```

## I. Vocabulary Growth

### Dataset Prep

```{r}
attach(vdata)
vdata$time = time0
vdata$time[time0==1] = 18; vdata$time[time0==2] = 21; vdata$time[time0==3] = 24; vdata$time[time0==5] = 30
vdata$time0 = vdata$time-18
vdata$sex = factor(sex,levels=c(0,1),labels=c("Male","Female"))
detach(vdata)

contrasts(vdata$sex) = c(-1,1) # Use effect coding, we are interested in the overall, and whether females are higher

vdata_s = vdata[order(vdata[,1],vdata[,5]),]
vdata_s = vdata_s[1:40,] # Keeps ~10 subjects
```

### Dataset Information

`vdata` from Dr. Adrian Weisleder, with permission. Young children (N=324) were assessed at four time points beginning at 18 months, to determine their vocabulary size over time. From the questions in the final I have prepared analysis to show the following major points:
  (1) Is the relationship between vocabulary size and time linear or non-linear? *Analysis done with a linear regression, wordsprod ~ time, accounting for repeated measures across subjects*
  (2) Is there variation across children in how vocabulary changes? *Analysis done on a small random sample of subjects using lmer, wordsprod ~ time + (1 + time | Sub)*
  (3) Can differences between children be explained by their sex? *Analysis done by including a regressor for sex, wordsprod ~ time + sex + (1 + time | Sub)*
  
### I. 1: Does vocabulary size increase over time?

### Plot a

Let's first take a look at whether there may be an interaction of sex on the effect of time on vocabulary size.

```{r}
interaction.plot(x.factor=vdata$time,trace.factor=vdata$sex,response=vdata$wordsprod)
```

The plot suggests there may be an additive effect. We will conduct statistical analyses later to quantify this, but for the time being we will put it to the side.

### Plot b

Let's take a look to see what we might expect from this data, just using a small sample of 20 children.

```{r}
ggplot(vdata_s,aes(time,wordsprod,color=factor(Sub),group=Sub)) +
  geom_point() +
  geom_smooth(method="lm",formula=y~x,color="orange",alpha=.05) +
  theme_bw()
```

As the plot shows, time and vocabulary size appear to show a linear relationship. In addition, it looks like individual children may have different starting intercepts for vocabulary size, but that they do not differ in their rate of vocabulary acquisition. We can test the linearity with a linear model, by comparing a model with $time$ alone to a model with $time + time^2$. By using a mixed model with subjects as a random effect we can account for the repeated measures design and get an estimate of the variability in the intercept. Note that we model the children as a random effect because we aren't interested in individual children's results, they are samples of a larger population of children in general to whom we would like to generalize our results.

```{r}
# Note, I'm using time0, which is just time moved to start at 0, so that the intercept is at the right height.
vrs1 = lmer(wordsprod ~ time0 + (1|Sub),vdata)
vrs2 = lmer(wordsprod ~ poly(time0,2) + (1|Sub),vdata)
anova(vrs1,vrs2)
```

The anova analysis comparing the two models: \
Vocab Size ~ Time with Vocab Size ~ Time + Time^2 \
suggests that the relationship is only linear, with no quadratic component, $\chi^2(1) = .02, p = .877$.

We can now proceed in our model comparison by looking at whether children's vocabulary size grew at different rates.

```{r}
vrs3 = lmer(wordsprod ~ time0 + (1 + time0 | Sub),vdata)
anova(vrs1,vrs3)
```

The anova analysis comparing the two models: \
Vocab Size ~ Time + (1|Sub) with Vocab Size ~ Time + (1 + Time|Sub) \
suggests that subjects do have variable learning rates, $\chi^2(2) = 27.29, p < .001$. We will proceed with the slope model.

Finally, we want to know whether sex has an impact on learning rate in the full model. We can look at this in our small sample with a second graph.

```{r}
ggplot(vdata_s,aes(time,wordsprod,color=sex,group=Sub)) +
  geom_point() +
  geom_smooth(method="lm",formula=y~x,alpha=.05) +
  theme_bw()
```

The plot (*note: same plot as above, sub-sample of full dataset, with sex colored*) suggests that there is a difference vocabulary size, possibly starting higher for females. There may also be a slope difference but it's hard to tell, but we can test for these. First we can check for an overall effect, then we can check for possible interactions.

```{r}
vrs4 = lmer(wordsprod ~ time0 + sex + (1 + time0 | Sub),vdata)
vrs5 = lmer(wordsprod ~ time0 * sex + (1 + time0 | Sub),vdata)
anova(vrs3,vrs4,vrs5)
```

Our model comparison identifies the model including sex, but not including an interaction as the best model (rs4 > rs3, $\chi^2(1) = 6.65, p = .010; rs5 > rs4$, $\chi^2(1) = .50, p = .481$). We will proceed with analyzing the best model.

```{r}
summary(vrs4)
```

We analyzed a dataset to discover how vocabulary size changes during the first two years of life. To do this we computed a linear regression predicting vocabulary size for children from 18 months old to 30 months, using age (18,21,24,30, repeated measure within subject) and sex (male,female, between subject) as fixed effects, as well as including random intercepts (initial vocabulary) and slopes (rate of learning) effects for subjects. We found that children do increase the size of their vocabulary across their second year of life, from an initial size of ~77.13 words, increasing by 35.49 words per month (425.88 words per year), $\beta_{time0} = 35.49, t(80.11) = 27.23, p < .001$. In addition, female children began with a higher vocabulary, with approximately 40% more words and maintained this difference over time compared to male children, $\beta_{sex1} = 32.34, t(79.82) = 2.61, p = .011$. There was considerable variability across children's initial vocabulary size, with a 95% confidence interval of `r p(quantile(vdata$wordsprod[vdata$time0==0],c(.05,.95)))`. Nonetheless, there was only a small variability in learning rates by comparison, $\sigma = 7.91$, an order of magnitude smaller than the variability in initial size $\sigma = 95.46$. 

In conclusion, and in response to the interests of researcher **RA**, we found that children do learn a considerable amount of vocabulary during their first two years of life **a** and that their learning rate is linear across this time period. Starting from ~75 words children, on average,  increase their total vocabulary to ~500 words by 30 months of age. **b** The large variability we observed in vocabulary across children is driven by variability in the relative vocabulary size across children (intercept), and to a lesser extent by the learning rate (slope). At 18 months 90% of the studied children knew between 5 and 220 vocabulary words, at 30 months 90% of the studied children knew between 200 and 670 words. **c** Finally, there is a gender bias, where female children start and end with a larger vocabulary, although they do not learn at a different rate compared to male children.

## II Interaction Within Couples

### Dataset Prep

```{r}
cdata = read.csv("http://web.stanford.edu/class/psych252/data/couples1.csv")
attach(cdata)
cdata$counsel = factor(counsel,levels=c(0,1),labels=c("No","Yes"))
cdata$counrep = factor(counrep,levels=c(0,1),labels=c("No Resp","Resp"))
cdata$agef = factor(age,levels=c(1,2,3),labels=c("<25","25-35",">35"))
cdata$educ = factor(educ,levels=c(1,2,3),labels=c("HS Dropout","College Dropout","1 Finished College"))
cdata$incom = incom * 1000
cdata$train = factor(train,levels=c(0,1),labels=c("No Training","Training"))
cdata$id = 1:150
detach(cdata)
```

### Dataset Information

A large study was conducted on *couples* (N=150) investigating the 'quality of interaction' between the partners. Several demographics including age, education, and income were surveyed. In addition couples were placed into either a training group that received conflict resolution and empathic response training (etc) or no training. Also surveyed was the "self-concept" of each couple just prior to judging of interaction quality and whether participants had previously received counseling. There are several interesting theoretical questions:

  Researcher **R1** wants to know whether interaction quality depended on prior counseling, but observed that the response rate was low in this study. **R1** also wants to know whether response rate depended on participant demographics and whether these might the demographics might be moderating the effect of counseling on interaction quality.
  Researcher **R2** wants to know whether the study's training manipulation was successful, noting that demographics may also affect interaction quality.
  Researcher **R3** believes that the effect of training on quality is mediated by self-concept, specifically: training increases self-concept, which increases interaction quality.
  Researcher **R4** is interested in how the demographics in this data set interact. **R4** believes that age and education may determine income, as well as postulating a possible influence of interaction quality (a measurement of social skill) on income.
  
### **R1**: quality ~ counseling & counseling ~ demographics

Let's investigate whether quality of interactions depends on counseling.

```{r}
cr0 = lm(quality ~ counsel,cdata,na.action=na.omit)
noNA = na.omit(cdata)
ggplot(noNA,aes(counsel,quality,group=1)) +
  geom_point() +
  geom_smooth(method="lm") +
  theme_bw()
summary(cr0)
```

The plot shows that there may be an effect, but unfortunately the effect size is quite small and it turns out to be only marginal, `r apaprint(cr0,coefs="counselYes")`. It's difficult to interpret this result though because the couples that responded may differ in some ways from those that didn't respond. To test for this let's investigate whether there are factors that influence the choice to respond. If we don't find any differences we might concluce that the sub-sample used to check the impact of counseling on quality is representative of the larger sample in the study.

**R1** also wants to know whether the choice to respond depends on demographics

```{r}
contrasts(cdata$educ) = cbind(c(-1,0,1),c(-1,2,-1))
cr00 = glm(counrep ~ 1, cdata, family = "binomial")
cr1 = glm(counrep ~ age,cdata,family="binomial")
cr2 = glm(counrep ~ age+educ,cdata,family="binomial")
cr3 = glm(counrep ~ age+incom,cdata,family="binomial")
anova(cr00,cr1,cr2,cr3,test="Chisq")
```

An anova analysis showed that including age as a predictor of response did significantly improve the model, $p = .030, but additional predictor variables were uninformative. We can proceed by looking at how well the model predicting counseling response from age represents the data.

```{r}
xr = seq(1,3,.01)
ggplot() +
  geom_smooth(data=cdata,aes(age,as.numeric(counrep)-1),method='glm',color='orange') +
  geom_point(data=cdata,aes(age,as.numeric(counrep)-1,color=counrep),
             position=position_jitter(width=.05,height=.05)) +
  scale_x_discrete(limits=levels(cdata$agef)) +
  theme_bw()
summary(cr1)
```

As the plot shows the model does not do a great job of capture the variance in the data, since it wouldn't predict any "yes" responses to counseling from age alone. But it does suggest that younger couples were more likely to respond to the question than older couples. Indeed, age was a significant predictor of response, `r apaprint(cr1,coefs="age")`.

This allows us to revisit the original effect we found, suggesting that the observed effect of previous counseling on quality (moderately positive), is biased by younger couples who were much more likely to respond to the question. We should find a better sample to ensure that our results here are generalizable across a larger population.

```{r}
cdata_young = na.omit(cdata[cdata$age==1,])
cr0y = lm(quality ~ counsel,cdata_young,na.action=na.omit)
ggplot(cdata_young,aes(counsel,quality,group=1)) +
  geom_point() +
  geom_smooth(method="lm") +
  theme_bw()
summary(cr0y)
```

Indeed, when considering only the young population, of which we have the best sample size, there does seem to be a significant effect for previous counseling on interaction quality, `r apaprint(cr0y,coefs="counselYes")`. The result is based on a sample size of N=13, so we should consider re-running the study with a better counseling response to ensure that the results are accurate.

In conclusion for **R1**, interaction quality does depend on previous counseling among young couples, with no conclusion for the other age ranges. In addition, response rates depend in small part on age but not on education level or income. This study was not well designed to look at **R1**'s questions and they might consider creating a study where responses to the prior counseling question are the main focus to address their questions. 

### **R2**: quality ~ training + demographics

To investigate the effect of training and demographics on quality, we will begin with a model comparison to evaluate the appropriate model to include.

```{r}
cr4 = lm(quality ~ 1,cdata)
cr5 = lm(quality ~ train,cdata)
cr6 = lm(quality ~ train + age,cdata)
anova(cr4,cr5,cr6)
```

we evaluated three incresingly complex models predicting quality from training and age and found that both the addition of training and age generated models that were significanlty better when accounting for the increase in degrees of freedom (all $p < .001$).

Age might have non-linear effects, which we can test for.

```{r}
cr7 = lm(quality ~ train + poly(age,2),cdata)
anova(cr6,cr7)
```

Our model analysis suggests that age does not have a quadratic effect. Indeed, the coefficient of the quadratic term was not found to be significant, `r apaprint(cr7,coefs="poly(age, 2)2",co=T)`, and the model comparison suggests that no additional variance was captured ($p = .490$).

Two other demographic variables were surveyed, education level and income.

```{r}
cr7a = lm(quality ~ train + age + educ,cdata)
cr7b = lm(quality ~ train + age + incom,cdata)
anova(cr6,cr7a)
anova(cr6,cr7b)
```

Our model analysis suggests that neither adding education nor income accounts for more of the variance in interaction quality than training and age already captured ($p = .150$ and $p = .300$ respectively). Finally, there may be an interaction of training and age.

```{r}
cr8 = lm(quality ~ train * age,cdata)
anova(cr6,cr8)
```

Including an interaction effect in the model did not significantly improve the prediction, $F(146,1) < .01, p = .993$, and the model comparison suggests that no additional variance is explained, $p = .990$.

Let's plot the dataset using those predictors that were informative, training and age, and look at where we can further understand a quantify the interesting effects.

```{r}
ggplot(cdata,aes(train,quality,color=agef,group=agef)) +
  geom_point(position=position_jitter(width=.075,height=.05)) +
  geom_smooth(method="lm") +
  theme_bw()
summary(cr6)
```

In summary, we computed a linear regression predicting interaction quality from two variables: whether participants were placed in the experimental training group or the control group (no couples training), and their age. Quality of interaction decreased significantly with increasing age, older couples were likely to have the worst quality of interaction, `r apaprint(cr6,coefs="age",co=T)`. Training did improve the quality of interaction, increasing couple scores by ~1.7 points, `r apaprint(cr6,coefs="trainTraining")`.

In conclusion for **R2** we found that the training manipulation was successful: the experiment was successful and training does improve the ability of couples to interact positively as observed by third parties. 

### **R3**: quality ~ self-concept ~ training (mediation)

Researcher 3 wants to know whether the effect of training on interaction quality may be mediated by the measurement of self-concept, taken just before the observation of interaction quality. We can look at this by using two plots to see whether training leads to higher self concept, and whether higher self concept leads to higher interaction quality.
```{r}
ggplot(cdata,aes(train,selfcon,group=1)) +
  geom_point() +
  geom_smooth(method="lm") +
  ggtitle("Training Leads to Higher Self Concept") +
  theme_bw()
ggplot(cdata,aes(selfcon,quality)) +
  geom_point() +
  geom_smooth(method="lm") +
  ggtitle("Self-Concept Leads to Higher Interaction Quality") +
  theme_bw()
```

It appears that our hypothesis is correct and some of the effect of training on interaction quality is mediated by the indirect effect of self-concept. Leads check exactly how much:

Calculate mediation values.

```{r}
cr9 = lm(quality ~ train,cdata)
c = coefficients(cr9)[2]
cr10 = lm(selfcon ~ train,cdata)
a = coefficients(cr10)[2]
cr11 = lm(quality ~ train + selfcon,cdata)
cp = coefficients(cr11)[2]
b = coefficients(cr11)[3]
```

```{r}
library(semPlot)
semPaths(cr9 + cr10 + lm(quality~selfcon,cdata), "model", "est", 
         intercepts = FALSE, rotation=3, nCharNodes = 0, shapeMan = "rectangle", 
         sizeMan = 23, sizeMan2 = 4, edge.color = "black", 
         nodeLabels = c("  Train  ", "Interaction Quality","Couple Self Concept"),
         edgeLabel = c("c' = 0.01\n(c = 1.86***)","a = 4.54***", "b = .42***"), 
         edge.label.cex = 1,
         cardinal = T)
```

*Note: I'm not sure why I couldn't get "train" to be smaller in the graph. It shouldn't be huge like this.*

Clearly there is a huge effect, the direct effect goes to near 0 when the indirect effect of self concept is taken into account. In other words, the effect of training on self-concept is entirely responsible for the increase in interaction quality that is observed.

But Ewart likes p-values! So we can test this using the mediation_boostrap function to see whether it is significant with the prediction that it will be significant:

```{r}
mediation_bootstrap = function(x, med, y, iterations = 1000){
  
  # setup some parameters
  N = length(x)
  df = as.data.frame(cbind(x, med, y))
  boot_ab = vector(length=iterations) # set up empty vector for storage
  
  # now go through a loop where we'll randomly sample, and get a a*b value
  for (i in 1:iterations){
    ind_boot = sample(c(1:N), N, replace=TRUE) # random indices
    df_boot = df[ind_boot,]
    
    iter_a = lm(df_boot$med ~ df_boot$x)$coefficients[2] # coeff of x
    iter_b = lm(df_boot$y ~ df_boot$med + df_boot$x)$coefficients[2] # coeff of mediator
    
    boot_ab[i] = iter_a * iter_b
  }
  
  # create plot
  hist(boot_ab,main=paste("Bootstrapped a*b, with",iterations,"iterations"),col="red");
  abline(v=0, col='black', lty=2, lwd=2)
  abline(v=c(quantile(boot_ab,c(.025,.975))), col='blue', lty=3)
  
  # Print results
  print("Bootstrap results:",quote=F);
  print(c(ab=mean(boot_ab)));
  print(quantile(boot_ab,c(.025,.975)))
  
  return(boot_ab)
}
boots = mediation_bootstrap(cdata$train,cdata$selfcon,cdata$quality)
```

The mediation was found to be significant, every coefficient value obtained for a*b was greater than zero, (in the old fashioned way: p <<< .001).

In conclusion for **R3** the significant effect of training in the experiment on interaction quality is mediated by self-concept. Specifically: training increases self-concept, which increases interaction quality.

### **R4**: income ~ age + education + ?quality

Finally, researcher 4 wants to know about what happens to income. We will use a model comparison to understand how age, education, and possibly interaction quality influence income.

```{r}
cr12 = lm(incom ~ 1,cdata)
cr13 = lm(incom ~ educ,cdata)
cr14 = lm(incom ~ age + educ,cdata)
anova(cr12,cr13,cr14)
```

Our model analysis identifies education as an important factor in income, specifically the linear effect of education, but suggests that age does not account for more of the variance in income, $p = .001$ and $p = .135$ respectively.

```{r}
cr14 = lm(incom ~ educ + quality,cdata)
anova(cr13,cr14)
```

Interaction quality also was identified as a poor predictor of the variance in income, $F(146,1) = .001, p = .970$, and a model comparison reveals no additional variance is accounted for by income ($p = .97$).

```{r}
ggplot(cdata,aes(educ,incom,color=educ,group=educ)) +
  geom_boxplot() +
  theme_bw()
summary(cr13)
```

In summary, we computed a regression model predicting income from level of education and found a significant linear effect. HS dropouts on average earned ~55k per year, getting to college but not completing was sufficient to increase income by 8k per year, similarly graduating college was responsible for an additional 8k per year increase in income, `r apaprint(cr13,coefs="educ1")`. The other demographic measure, did not account for any additional variance in income. Interaction quality did not account for any additional variance in income.

In conclusion, **R4** was correct that education level is important for income at the time of the study, but incorrect that social interactions or age were driving income size.

### Conclusions Regarding the Couples Study

In regards to the main goal of the couples study, training is sufficient to improve interaction quality, but age also accounts for some of this variance `r apaprint(cr6,coefs=c("age","trainTraining"),co=T)`. This effect is due largely to the impact of training on self-concept within a couple, with a mean indirect effect of `r p(mean(boots))`, subsuming the entire direct of training on interaction quality. But interaction quality does not seem to have many downstream effects, for example it does not predict improved income, `r apaprint(cr14,coefs="quality",co=T)`. Further study will be necessary to understand whether interaction quality, was measured by this study, has impacts on other aspects of couple's lives--for example long-term divorce rates. In addition, this study's timeline may have been too short to capture every aspect of a couple's evolution over time.

We also found that among the young couples counseling was an additional important factor predicting quality of interaction, `r apaprint(cr0y,coefs="counselYes",co=T)`. Unfortunately the results could not be generalized to the full study population and further research will need to be done to evaluate the importance of previous counseling on interaction quality, and whether training bolsters this effect.

## Thank you!