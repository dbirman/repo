---
title: "birman_daniel_quiz1"
author: "Dan Birman"
date: "Friday, October 10, 2014"
output: html_document
---

Loading some background code here, see the .Rmd.

```{r echo=F}
library(ggplot2)
library(reshape)
pp = function(x) {round(x, digits=3)}
p = function(x) {round(x, digits=2)}
## APA Format Printing
## Author: Dan Birman
## 10/13/2014

apaprint = function(stat_obj, coefs=c(), stars=F) {
  so = class(stat_obj)
  if (length(so) > 1) {so = so[1]}
  switch(so,
         "htest" = phtest(stat_obj,stars),
         "lm" = .plm(stat_obj,coefs,stars),
         "glm" = .pglm(stat_obj,coefs,stars))
}

.pglm = function(s,coefs,stars) {
  #Warning this defaults 
  if (length(coefs)==0) {coefs = dimnames(summary(s)$coefficients)[[1]][2]}
  out_s = .lin_mod_coefs(s,coefs,stars)
  out_s
}

.plm = function(s,coefs,stars) {
  sm = summary(s)
  out_s = .lin_mod_coefs(s,coefs,stars)
  if (length(coefs)>=1) {paste(out_s,", ",sep="")}
  #Everything standard
  f = sm$fstatistic
  p = pf(f[1],f[2],f[3],lower.tail=F)
  r2 = sm$r.squared
  if (length(coefs)>0) {
  return(sprintf("%s$;  F_{(%.0f, %.0f)} = %.2f, %s, adj. R^2 = %.2f$",out_s,f[2],f[3],f[1],.pformat(p,stars),r2))
  }
  return(sprintf("$F_{(%.0f, %.0f)} = %.2f, %s, adj. R^2 = %.2f$",f[2],f[3],f[1],.pformat(p,stars),r2))
}

.lin_mod_coefs = function(s,coefs,stars) {
  sm = summary(s)
  co_s = c()
  if (length(coefs) >= 1) {
    for (i in 1:length(coefs)) {
      cur = coefs[i]
      dat = sm$coefficients[cur,]
      p = dat[4]
      ci = confint(s,cur)
      if (i > 1) {co_s = paste(", ",co_s,sep="")}
      co_s = paste(sprintf("$b_{%s} = %.2f, [%.2f %.2f], %s$",cur,dat[1],ci[1],ci[2],.pformat(p,stars)),co_s,sep = "")
    }
  }
  if (length(co_s)==0) {co_s = ""}
  co_s
}

.pformat = function(pv,stars) {
  if (stars==T) {
    if (pv >= .05) {return(sprintf("p = %.3f",pv))}
    if (pv >= .01) {return(sprintf("p = %.3f *",pv))}
    if (pv >= .001) {return(sprintf("p = %.3f **",pv))}
    return("p < 0.001 ***")
  }
  if (pv >= .05) {return(sprintf("p = %.3f",pv))}
  if (pv >= .01) {return(sprintf("p = %.3f",pv))}
  if (pv >= .001) {return(sprintf("p = %.3f",pv))}
  return("p < 0.001")
}

phtest = function(s,stars) {
  switch(s["method"]$method,
         "One Sample t-test" = .pttest(s,stars),
         "Welch Two Sample t-test" = .pttest(s,stars),
         "Pearson's Chi-squared test" = .pchisqp(s,stars),
         "Chi-squared test for given probabilities" = .pchisqp(s,stars),
         "One-way analysis of means (not assuming equal variances)" = .panova(s,stars),
         "Pearson's product-moment correlation" = .pcorr(s,stars)
  )
}

.panova = function(s,stars) {
  .basicprint(s,"F",stars)
}

.pchisqp = function(s,stars) {
  sprintf("$\\chi^2$(%.0f, N = %.0f) = %.2f, %s",s$parameter,s$parameter+1,s$statistic,.pformat(s$p.value,stars))
}

.pcorr = function(s,stars) {
  sprintf("*r* (%.0f) = %.2f, %s",s$parameter,s$estimate,.pformat(s$p.value,stars))
}

.pttest = function(s,stars) {
  .basicprint(s,"t",stars)
}

.basicprint = function(s,st,stars) {
  sprintf("*%s* (%.0f) = %.2f, %s",st,s$parameter,s$statistic,.pformat(s$p.value,stars))
}
```

As the handout suggests, there is *much* interest in fixing back pain. We will now consider a fictitious world in which we have access to all sorts of interesting variables such as (note, this is from http://web.stanford.edu/class/psych252/_downloads/acupuncture.csv, which we will use later):

    treatment: Treatment type (1 = 'real' acupuncture; 2 = traditional)
    exercise: Level of patient's exercise
    otc: Whether participants take over the counter medicine (1 = Yes, 2 = No)
    time: Elapsed time (in years) since symptom onset
    relief: Level of pain relief
  
###A

We are given a measure of reported pain for N patients all given the same treatment. Our null hypothesis ($H_0$) is that the patients received a traditional treatment (presumably "Physical Therapy"), our alternative hypothesis ($H_1$) is that participants received acupuncture.

  Assumption: On average pain reported in acupuncture is **the same or less than** under the traditional regimen, so we will use one-tailed tests.
  
Using the handout data I will set up some variables:

```{r}
mu0 = 4.9 # Expected value of X (pain reported) if H0=T
sig0 = 2.7 # Standard deviation of X if H0=T
mu1 = 2.8 # E(X) if H1=T
sig1 = 2.7 # SD(X) if H1=T
N = 9
alpha = .05
```

###A1

Our sample mean was $\bar{X} = 3.4$. We will now test if $H_0$ is true.

```{r}
xbar = 3.4
Zs = (xbar - mu0) / ( sig0 / sqrt(N) )
# Plotting
x = seq(0,10,.01)
d0 = dnorm(x,mean=mu0,sd=sig0/sqrt(N))
dat = data.frame(null=d0,x=x)
ps = pnorm(xbar,mean=mu0,sd=sig0/sqrt(N))
ggplot() +
  ggtitle("Distribution of Sampled Means (N=9)") +
  geom_line(data=dat,aes(x,null,color="blue")) +
  geom_vline(xintercept=xbar,color="red") +
  scale_color_manual(name="Hypothesis",values=c("blue"="blue","green"="green"),labels=c("Null","Alternative")) +
  annotate("text",label=paste("p = ",pp(ps)),x=1,y=.125)
```

We calculated the Z-score and tested the probability that our sample mean was taken from the H0 population.
$Z = (\bar{X} - \mu_0) / (\sigma / sqrt(N)) = (`r p(xbar)` - `r p(mu0)`) / (`r p(sig0)` / `r N`)  = `r p(Zs)`$

$P(`r p(Zs)`) = `r pp(ps)`$
Because the probability of observing this sample mean is less than our alpha $\alpha = `r alpha`$, we reject the null hypothesis and conclude that our sample was taken from a group that had acupuncture. Note that a *p* of ~ 0.05 is not very significant, but since this effect appears to be quite substantial (if pain was measured on a 1-10 scale for example) so we might speculate that this is an interesting effect that we should look into more clearly.

###A2

We want to know the value `c` such that we would reject H0 when $\bar{X} < c$ when $P(\bar{X} < c | \mu_0 = 4.9) = \alpha = `r alpha`$

```{r}
c = qnorm(alpha,mean=mu0,sd=sig0/sqrt(N))
```

In general we should reject $H_0$ when $\bar{X} < `r p(c)`$

###A3

We want to know the power of this test.

```{r}
cd = (mu1 - mu0) / sig0 # Note, sd is the same for both
pow = pnorm(c,mean=mu1,sd=sig1)
#plotting
d0 = dnorm(x,mean=mu0,sd=sig0/sqrt(N))
d1 = dnorm(x,mean=mu1,sd=sig1/sqrt(N))
dat = data.frame(null=d0,alt=d1,x=x)
ggplot() +
  ggtitle("Distribution of Sampled Means (N=9)") +
  geom_line(data=dat,aes(x,null,color="blue")) +
  geom_line(data=dat,aes(x,alt,color="green")) +
  geom_vline(xintercept=c,color="red") +
  scale_color_manual(name="Hypothesis",values=c("blue"="blue","green"="green"),labels=c("Null","Alternative"))
```

As the graph shows our power is the probability of correctly rejecting $H_0$ when it is false, this is equal to the probability of having our sample mean $\bar{X}$ less than the critical value. If the alternative hypothesis $H_1$ is true, then this is equal to the area under the alt hypothesis curve (green) left of the criterion $c = `r p(c)`$.

$P(\bar{X} < c | \mu_1 = `r p(mu1)`) = `r pp(pow)`$

###B

We are curious about how treatment type impacts the use of OTC medicines. Patients were either put in several Treatment conditions, real acupuncutre (1), sham acupuncture (2), or traditional exercise and PT (3). Use of OTC was either yes, patient used more than a minimum amount, or No, patient used a minimum amount of OTC. We have four interests

  (i) What proportion, *p*, of patients used OTC medication and what is our margin of error.
  (ii) Does the sample show evidence of differential attrition between Treatment conditions (original proportions were 1=.3, 2=.3, 3=.4)
  (iii) What is the relationship between Treatment and Use of OTC Meds?
  (iv) If there is an effect is it due to the presence of needles (sham effect) or is it evidence that proper needle placement is important?
  
###B1

Let's set up the data into a table:
```{r}
dtable = as.table(matrix(data=c(57,51,72,46,27,17),nrow=2,ncol=3,byrow=T))
names(attributes(dtable)$dimnames) = c("OTC","Treatment")
attributes(dtable)$dimnames$Treatment = c("Acu","Sham","Trad")
attributes(dtable)$dimnames$OTC = c("Yes","No")
```

###B2 - Question (i)

We will calculate the proportion of respondents with $OTC = "Yes"$. Margin of error is approximately $1 / sqrt(N)$

```{r}
N = sum(dtable)
otc_y = sum(dtable["Yes",])/N
moe = 1/sqrt(N)
```

$P(OTC = "Yes") = `r pp(otc_y)` \pm `r pp(moe)`$

###B3 - Question(ii)

We will use a chisq.test with given probabilities to test whether the treatment groups show different attrition rates, regardless of the use of OTC medication.

```{r}
# For some reason I can't get this code to work:
#rs = chisq.test(dtable,p=c(.3,.3,.4,.3,.3,.4),rescale.p=T)
# So I use this instead:
tTable = as.table(colSums(dtable))
rs = chisq.test(tTable,p=c(.3,.3,.4))
```

A Chi-squared test for given probabilities was performed and found a significant difference between the expected probabilities and the Treatment group sizes, `r apaprint(rs)`, suggesting that the groups have different attrition rates. 

```{r}
dat = data.frame(value=rs$observed)
names(dat) = c("Treatment","value")
dato = dat
dato$value = unname(rs$expected)
fdata = rbind(dat,dato)
fdata$Expected = c(0,0,0,1,1,1)
fdata$Expected = factor(fdata$Expected,levels=c(0,1),labels=c("Observed","Expected"))
# Again I had some trouble figuring out how to do this properly... oh well
ggplot(fdata,aes(Treatment,fill=Expected,y=value)) +
  ggtitle("Differential Attrition Rates due to Treatment Group") +
  geom_bar(position="dodge",stat="identity")
```

We can see that this effect is driven by differences among the patients in the Acupuncture and Traditional treatment groups. Traditional patients were more likely to leave the study, while Acupuncture patients were more likely to stay in the study than expected. We might speculate that this is because acupuncture is effective while traditional medicine was ineffective (leading the patients to leave and try other options).

###B4 - (Question iii)

We are looking for a relationship between Treatment (Categorical) and Use of OTC Medicine (Binary). We can check for a relationship by using a Chi-squared test.

```{r}
rs = chisq.test(dtable)
print(rs)
```

We performed a $\chi^2$-test for independence on the null $H_0$ that Treatment and Use of OTC medication are independent. The results indicate that we can rule out the null $H_0$, `r apaprint(rs)`.

```{r echo=F}
dtable
```

We might speculate that this is driven by an interaction (see table), since traditional treatment seems to predict a very high rate of OTC use, whereas acupuncture does not seem to be a strong predictor of OTC use.


###B5 - (Question iv)

Plotting...

```{r}
dat = melt(dtable)
dat = cbind(0,dat)
names(dat)[1] = "Expected"
dato = dat
dato$Expected = c(1,1,1,1,1,1)
dato$value = c(.3,.3,.3,.3,.4,.4) * c(180,90,180,90,180,90)
fdata = rbind(dat,dato)
fdata$Expected = factor(fdata$Expected,levels=c(0,1),labels=c("Observed","Expected"))
# Setting up that data structure was a mess, what I really wanted to do was add the expected values as a 3rd dimension in dtable, and then melt that directly, but I couldn't figure that out. If you know how to do this more cleanly please let me know!
ggplot(fdata,aes(Treatment,fill=Expected,y=value)) +
  ggtitle("Differential Attrition Rates due to Treatment Group and OTC Med Use") +
  geom_bar(position="dodge",stat="identity") +
  facet_grid(.~OTC)
```

It looks like attrition rate is mediated by an interaction between OTC medication use and Treatment group. In short, we didn't observe differential attrition rates when participants were using OTC medications, when they were not we see differences. Of particular interest is that the attrition rate is high for traditional treatment, suggesting that patients did not get pain relief from participating in the study. Sham acupuncture seems to relieve this effect, possibly due to a placebo effect. Actual acupuncture has a lower attrition rate than expected, possibly due to a difference between actual acupuncture success vs. sham.

###C

Dataset overview:

    treatment: Treatment type (1 = 'real' acupuncture; 2 = traditional)
    exercise: Level of patient's exercise
    otc: Whether participants take over the counter medicine (1 = Yes, 2 = No)
    time: Elapsed time (in years) since symptom onset
    relief: Level of pain relief

```{r}
data = read.csv("http://web.stanford.edu/class/psych252/_downloads/acupuncture.csv")
data$otcF = factor(data$otc,levels=c(1,2),labels=c("Yes","No"))
data$treatment = factor(data$treatment,levels=c(1,2),labels=c("Acu","Trad"))
```

###C-1

We want to know whether patients were assigned to the acupuncture treatment group because of their level of exercise or time since symptom onset. We can look at this by testing whether *treatment* level depends on either *exercise* or *time*. Because *treatment* is a binary variable we will use logistic regression.

```{r}
rs1 = glm(treatment ~ exercise,data,family="binomial")
rs2 = glm(treatment ~ time,data,family="binomial")
rs3 = glm(treatment ~ time + exercise,data,family="binomial")
rs4 = glm(treatment ~ time * exercise,data,family="binomial")
```

Before investigating these models in detail, we can potentially rule out the more complex models in advance.

```{r}
com_rs = anova(rs1,rs2,rs3,rs4,test="Chisq")
print(com_rs)
```

As the table shows, the third model captures the data best with a minimum increase in parameters. This also implies that time and exercise do not interact to affect treatment type. Let's look at the model more clearly.

```{r}
summary(rs3)
```

The GLM analysis shows that treatment group depends on time since initial symptom onset, `r apaprint(rs3,coefs="time")`, and that treatment group also depends on current levels of exercise, `r apaprint(rs3,coefs="exercise")`. Higher levels of exercise appear to increase the probability of being placed in the traditional treatment group. Longer lengths of time since symptom onset increase the probability of being placed in the acupuncture group.

###C2

Does acupuncture succeed at treating lower back pain better than a traditional regimen? This is a categorical variable predicting a quantitative one.

```{r}
rs5 = lm(relief ~ treatment,data)
summary(rs5)
ggplot(data,aes(treatment,relief)) + geom_boxplot() +
  ggtitle("Effect of Treatment Group on Back Pain Relief")
```

We performed a linear regression to investigate the influence of treatment type on back pain relief and found a significant difference between treatment groups, `r apaprint(rs5,coefs="treatmentTrad")`. This is contrast is a difference of means: Traditional - Acupuncture. As we can see the slope is negative, suggesting that acupuncture results in more pain relief than the traditional treatment and that the difference is significant at *p* < 0.05. The effect is small, relief appears to be on a 0-10 scale, and the use of acupuncture is only responsible for 1/3 of a point difference.

###C3

We are concerned that our finding that treatment group placement was not random is causing downstream effects on the pain relief measures. We can investigate this by extending our linear model to use further regressors, looking at whether these diminish the effect of treatment group on relief.

(*note*: we can also look at this by just seeing how treatment group depends on exercise and time, but this approach ensures that any remaining variance that treatment group explains gets tested for significance.)

```{r}
rs6 = lm(relief ~ treatment + exercise,data)
rs7 = lm(relief ~ treatment + time,data)
rs8 = lm(relief ~ treatment + time + exercise,data)
summary(rs6)
summary(rs7)
summary(rs8)
```

We ran three linear models to analyze the dependency of relief on treatment, exercise, and time. All three models showed significance, but their analysis is more complex. The model with both treatment group and exercise as regressors shows that a portion of the variance that treatment group accounted for is shared with exercise, `r apaprint(rs6)`. The model with treatment group and exercise also shows that a portion of the variance that treatment group accounted for is shared with time, `r apaprint(rs7)`. To disentangle these we ran a third model with both time and exercise as regressors (note, we know these do not interact). The third model shows that time is the underlying factor responsible for all of these results, `r apaprint(rs8,coefs="time")`.

```{r}
ggplot(data,aes(time,relief,fill=treatment,color=treatment)) +
  geom_point() +
  geom_smooth(method="lm") +
  ggtitle("Influence of Length Since Back Pain Onset on Relief")
```

Combined with the previous results we now see that although both time since symptom onset and exercise level influenced treatment group placement, only time accounts well for the amount of relief patients received. Patients who have had longer since symptom onset received much more relief regardless of treatment group.

###4a & 4b

We now understand that relief is mostly dependent on length of time since symptom onset, so we can put that aside. How is the use of OTC medication related to relief (**4a**) and treatment group (**4b**)?

To dis-entangle these effects we will run new generalized linear models, since OTC use is a binary variable.

```{r}
rs9 = glm(otcF ~ relief,data,family="binomial")
summary(rs9)
ggplot(data,(aes(relief,otc-1))) + 
  geom_point() + 
  geom_smooth(method="glm",family="binomial") + 
  ggtitle("Sigmoid Curve Fit for OTC Use vs. Back Pain Relief")
```

We ran a generalized linear model to investigate the dependence of OTC use on level of relief received and found a significant relationship, `r apaprint(rs9,coefs="relief")`. Patients who reported higher levels of relief were more likely to report the use of OTC medications. As researcher 4 points out we can't be certain of causality, but we might speculate that the use of OTC medication is responsible for some portion of the variance in relief.

```{r}
rs10 = glm(otcF ~ treatment,data,family="binomial")
summary(rs10)
ggplot(data,(aes(treatment,otc-1,group=1))) + geom_point() + geom_smooth(method="glm",family="binomial") + geom_jitter(position=position_jitter(width=.1,height=.1)) + ggtitle("Sigmoid Curve Fit for OTC Use vs. Treatment Group")
```

We ran a generalized linear model to investigate the dependence of OTC use on treatment group assignment and found a significant relationship, `r apaprint(rs10,coefs="treatmentTrad")`. Patients who were in the traditional treatment group were less likely to also have used OTC medication, while participants in the acupuncutre group were more likely to have used OTC medication. We might speculate that this is due to the efficacy of the different treatments.

###5: *My Theory*

```{r}
ggplot(data,aes(time,relief,fill=otcF,color=otcF)) + 
  geom_point() +
  geom_smooth(method="lm") +
  ggtitle("Influence of Time Since Onset, OTC Use on Experienced Relief")
```

The results so far suggest that:
  (1) Treatment group assignment was non-random
  (2) The non-random assignment, influenced by time since symptom onset, is responsible for most of the relief of symptoms
  (3) OTC medication seems to mediate the effect of time since symptom onset on relief experienced.

My interpretation is that back pain relief occurs naturally over time and that use of OTC medications are prolonging back pain. A possible explanation is that experiencing pain encouraged participants to avoid painful actions, which eventually allowed them to naturally recover, while the use of OTC medications allowed them to continue their damaging activities, prolonging their recovery.

###D

```{r}
mdata = read.csv("http://web.stanford.edu/class/psych252/_downloads/metanalysis.csv")
```

We have the data from a meta-analysis with the following information:

    effect_size: Cohens d such that positive values indicate that acupuncture groups did better than control groups
    total_N: Total number of patients involved in the study
    symptoms: The primary symptom the patient was being seen for

###D1

We can start by calculating some summary statistics on effect size:

```{r}
md = mean(mdata$effect_size)
CI = confint(lm(mdata$effect_size~1))
```

The mean effect size was `\bar{x} = `r p(md)`, 95% CI [`r p(CI)`]. The confidence interval tells us that on average across these studies there was a small effect, significant at *p* = 0.05.

###D2

```{r}
ggplot(mdata,aes(symptoms,y=effect_size,color=symptoms)) +
  geom_boxplot() +
  ggtitle("Variation in Effect Size due to Symptoms Studied")
```

We want to know whether the differences, shown in the boxplot, are significantly different from 0. We can test this for each group:

```{r}
rs20 = lm(effect_size ~ symptoms - 1,mdata)
summary(rs20)
```

We ran a linear model comparing each symptom group's mean against a null hypothesis $H_0$ that the true mean was zero with unknown variance. The result was non-significant, with a marginally significant result for headaches, `r apaprint(rs20,coefs="symptomsheadaches")`. Because the effect size was quite large for headaches and we can see that there are some outliers pulling the result down we might speculate that there may be a real effect here but that there are serious differences between groups.

###D3

We want to know whether our studies were powerful enough to capture the effect. Let's calculate the power of each study individually, using the average value of *d* = `r p(md)` was the true effect size.

```{r}
mdata$power = power.t.test(n=mdata$total_N,delta=md)$power
mp = mean(mdata$power)
```

The mean power in our sample was $\bar{power}$ = `r p(mp)`. This is lower than  ideal, and suggests that this sample may only reflect a portion of the studies performed, as many would have failed to show statistical significance. Furthermore, this sample of significant results suggests that our estimate of effect size is larger than the true effect. 

###D4

We want to further know whether symptom type has an influence on number of patients or the average power of studies.

```{r}
ggplot(mdata,aes(symptoms,y=total_N,color=symptoms)) + geom_boxplot() + ggtitle("Variations in Participant Numbers due to Symptom Studied")
rs21 = lm(total_N ~ symptoms,mdata)
summary(rs21)
```

The graph suggests that neck pain and osteoarthritis might show differences. We ran a linear regression contrasting these against back pain and found significant differences with neck pain having significantly more patients than back pain and osteoarthritis having significantly less than back pain, `r apaprint(rs21,coefs=c("symptomsneck pain","symptomsosteoarthritis"))`. Let's look at whether these effects translated into the power analysis:

```{r}
ggplot(mdata,aes(symptoms,y=power,color=symptoms)) + geom_boxplot() +ggtitle("Power Variations due to Symptom Studied")
rs22 = lm(power ~ symptoms,mdata)
summary(rs22)
```

Similarly, since power depends on number of participants, a linear regression of the power data suggests that there is also difference in power across different studies when looking at symptoms. Specifically, neck pain studies had significantly higher power than back pain while osteoarthritis studies had significantly lower power than back pain, `r apaprint(rs22,coefs=c("symptomsneck pain","symptomsosteoarthritis"))`. Both effect sizes are small differences in power, but it suggests that the osteoarthritis studies in particular are very underpowered, while the neck pain results suggest that a true effect exists. We might consider one final analysis testing power against 0 but controlling for symptoms:

```{r}
rs23 = lm(power ~ symptoms - 1,mdata)
summary(rs23)
```

As expected we now see that the effect size estimates all differed from 0 and that the variance in power is well explained by symptom group. We performed a linear regression comparing the mean power of the symptoms groups against a mean of 0, finding significant effects across all groups, `r apaprint(rs23,coefs=c(dimnames(summary(rs23)$coefficients)[[1]]))`.